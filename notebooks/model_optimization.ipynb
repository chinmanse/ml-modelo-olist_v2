{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization and Presentation\n",
    "\n",
    "This notebook performs hyperparameter tuning for XGBoost and Random Forest models, compares their performance against a baseline Linear Regression model, and visualizes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path to import src modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.ingestion import load_data\n",
    "from src.preprocessing import preprocess_data, encode_categorical, handle_missing_values\n",
    "from src.feature_engineering import feature_engineering\n",
    "from src.optimization import get_baseline_model, tune_random_forest, tune_xgboost, compare_models\n",
    "from src.visualization import plot_model_performance, plot_predictions, plot_feature_importance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/raw/dataset_v4.csv. Shape: (116573, 47)\n",
      "Selected Features: ['customer_geolocation_lat', 'order_purchase_timestamp_month', 'freight_value', 'customer_geolocation_lng', 'customer_geolocation_zip_code_prefix', 'customer_zip_code_prefix', 'review_score', 'seller_geolocation_lng', 'seller_zip_code_prefix', 'seller_geolocation_zip_code_prefix', 'seller_geolocation_lat', 'payment_value', 'order_purchase_timestamp_year', 'price', 'product_weight_g', 'order_purchase_timestamp_day', 'product_height_cm', 'product_width_cm', 'product_length_cm', 'order_purchase_timestamp_dayofweek']\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "file_path = \"../data/raw/dataset_v4.csv\"\n",
    "df = load_data(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "df = preprocess_data(df)\n",
    "df = handle_missing_values(df)\n",
    "\n",
    "# Feature Engineering\n",
    "df = feature_engineering(df)\n",
    "df = encode_categorical(df)\n",
    "\n",
    "# Load selected features\n",
    "feature_shortlist = pd.read_csv('../data/processed/feature_shortlist.csv')['feature'].tolist()\n",
    "print(f\"Selected Features: {feature_shortlist}\")\n",
    "\n",
    "# Prepare X and y\n",
    "target_col = 'delivery_time_days'\n",
    "X = df[feature_shortlist]\n",
    "y = df[target_col]\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Model (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Linear Regression trained.\n"
     ]
    }
   ],
   "source": [
    "lr_model = get_baseline_model(X_train, y_train)\n",
    "print(\"Baseline Linear Regression trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning Random Forest...\")\n",
    "rf_tuned = tune_random_forest(X_train, y_train)\n",
    "\n",
    "print(\"Tuning XGBoost...\")\n",
    "xgb_tuned = tune_xgboost(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': lr_model,\n",
    "    'Random Forest (Tuned)': rf_tuned,\n",
    "    'XGBoost (Tuned)': xgb_tuned\n",
    "}\n",
    "\n",
    "results_df = compare_models(models, X_test, y_test)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "plot_model_performance(results_df)\n",
    "\n",
    "# Predictions vs Actuals (for best model)\n",
    "best_model_name = results_df.loc[results_df['RMSE'].idxmin()]['Model']\n",
    "best_model = models[best_model_name]\n",
    "y_pred = best_model.predict(X_test)\n",
    "plot_predictions(y_test, y_pred, best_model_name)\n",
    "\n",
    "# Feature Importance\n",
    "plot_feature_importance(best_model, feature_shortlist, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Justification for Model Selection\n",
    "\n",
    "### Why Random Forest / XGBoost?\n",
    "- **Non-linearity**: Delivery times often have non-linear relationships with features like distance or time of year, which linear models fail to capture effectively.\n",
    "- **Robustness**: Tree-based models are generally robust to outliers and scale differences, although we did some preprocessing.\n",
    "- **Feature Importance**: They provide interpretability through feature importance scores, which is crucial for business insights.\n",
    "\n",
    "### Tuning Results\n",
    "We used RandomizedSearchCV to find optimal hyperparameters. The tuned models show improved performance (lower RMSE) compared to the baseline and default configurations. The specific parameters chosen help prevent overfitting (e.g., `max_depth`, `min_samples_split`) while maximizing predictive power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
